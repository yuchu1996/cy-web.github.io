{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of a3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuchu1996/cy-web.github.io/blob/master/Copy_of_Copy_of_a3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWOHRLs9LRPI",
        "colab_type": "text"
      },
      "source": [
        "# A3: TensorBoard\n",
        "\n",
        "## About\n",
        "\n",
        "In this assignment, you will design and run experiments to evaluate the impact of a few common parameters (like the choice of activation function, optimizer, and weight initialization strategy) and visualize the results in TensorBoard.\n",
        "\n",
        "The starter code below shows the mechanics of using TensorBoard in Colab. Unlike the previous assignments, a limited amount of starter code is provided.  3c is an extra credit question, it's optional (you can receive full credit on this assignment without submitting it).\n",
        "\n",
        "## Questions\n",
        "\n",
        "### 3a. \n",
        "**Implement ReLU and compare against a previous activation function**.\n",
        "\n",
        "The year is 2010. It is not commonly known that ReLU is a useful alternative to activation functions like Sigmoid or Tanh (nor has ReLU been implemented in the library you're using). Create a DNN to classify MNIST, and provide your own implementation of ReLU (instead of using a built-in method). Design and run an experiment to compare ReLU against other methods, and use TensorBoard to display your results. What differences do you observe, and why?\n",
        "\n",
        "### 3b. \n",
        "\n",
        "**Optimizer and initalizer and soup**.\n",
        "\n",
        "Do optimizers like Momentum or Adam really make a difference? How about different weight initialize strategies (like random normal, or glorot uniform?) Design and run experiments to find out, and use TensorBoard to display your results. What differences do you observe, and why?\n",
        "\n",
        "### 3c. Extra credit (optional)\n",
        "\n",
        "**Demonstrate the vanishing gradient problem**. \n",
        "\n",
        "Implement an especially deep neural network and train it on a simple dataset like MNIST. Choose activation functions, initialization strategies, and an optimizer that are likely to cause this behavior. Produce histograms of activations and gradients at various layers during training. What do you see? Next, adjust the parameters above to correct this behavior. Visualize and compare the results.\n",
        "\n",
        "## Submission instructions\n",
        "\n",
        "Please submit your assignment on CourseWorks by uploading a zip file that includes:\n",
        "\n",
        "* A Jupyter notebook, containing complete code to reproduce your experiments, and saved output showing your results.\n",
        "\n",
        "* A README file (plaintext is fine). This should contain your written conclusions for each question. These can be brief (a couple paragraphs). Try to be specific in your answers (if ReLU outperfoms sigmoid, try to answer why).\n",
        "\n",
        "* Plots / diagrams (.jpgs). Since it is not convenient to save TensorBoard diagrams directly in a Jupyter notebook, you can take screenshots of your plots and submit them along with your Jupyter notebook in a zip file on CourseWorks. Please name your diagrams appropriately, and refer to them names in your notebook.\n",
        "\n",
        "If you are working in Colab, you can prepare your notebook for submission by ensuring that runs end-to-end, then saving and downloading it:\n",
        "\n",
        "1. ```Runtime -> Restart and run all```\n",
        "1. ```File -> Save```\n",
        "1. ```File -> Download.ipynb```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSc6v5ws8wKS",
        "colab_type": "text"
      },
      "source": [
        "## Starter code for TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE5lIlzkEUAv",
        "colab_type": "code",
        "outputId": "a8276041-1d03-489c-da2e-47d9eead89e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpe_UINKKLDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4sUrkaeKQSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehUDr72LLAJY"
      },
      "source": [
        "**Caution**. The following cell will clear the logs directory. If you're running this on your local machine, be careful executing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjIcVAJKkmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./tensorboard-logs/ # Clear any logs from previous runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ6aWI_NLm6C",
        "colab_type": "text"
      },
      "source": [
        "Import a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByT9RfkIK4kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2_huYeq80tv",
        "colab_type": "text"
      },
      "source": [
        "## First style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMLofsyiLthK",
        "colab_type": "text"
      },
      "source": [
        "Define a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHBo5cgTLuis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oEDGbBRMI-_",
        "colab_type": "text"
      },
      "source": [
        "Create a logs directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggu_lZRnL6Uf",
        "colab_type": "code",
        "outputId": "4558d26a-c433-4d00-a57e-15ea9ff7a296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import datetime \n",
        "import os\n",
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191029-003548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_icHggivMBXe",
        "colab_type": "text"
      },
      "source": [
        "### Run an experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyVj4vmLM0Yw",
        "colab_type": "code",
        "outputId": "854cc23b-8093-4b13-e3cc-038bdbf0f17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = create_model() \n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False) \n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"exp1\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=1, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 2.5281 - accuracy: 0.5613 - val_loss: 1.4181 - val_accuracy: 0.7648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f285050bc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6-cL05DN9fR",
        "colab_type": "text"
      },
      "source": [
        "### Run a second experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XVPmrpeN_u7",
        "colab_type": "code",
        "outputId": "f33c9ed9-4d86-47b9-8157-e55f7add5f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model() \n",
        "opt = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"exp2\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.9131 - accuracy: 0.8047 - val_loss: 0.4883 - val_accuracy: 0.8794\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.4635 - accuracy: 0.8796 - val_loss: 0.4039 - val_accuracy: 0.8956\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.4074 - accuracy: 0.8898 - val_loss: 0.3697 - val_accuracy: 0.9018\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3797 - accuracy: 0.8964 - val_loss: 0.3506 - val_accuracy: 0.9062\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3625 - accuracy: 0.9003 - val_loss: 0.3376 - val_accuracy: 0.9090\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3501 - accuracy: 0.9036 - val_loss: 0.3287 - val_accuracy: 0.9092\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3409 - accuracy: 0.9057 - val_loss: 0.3212 - val_accuracy: 0.9123\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3334 - accuracy: 0.9077 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3273 - accuracy: 0.9092 - val_loss: 0.3115 - val_accuracy: 0.9152\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3224 - accuracy: 0.9109 - val_loss: 0.3071 - val_accuracy: 0.9157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f28089aff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_pSh18ZOENe",
        "colab_type": "text"
      },
      "source": [
        "### Start TensorBoard and compare the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRkOYWn7OGGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPLDEq8MSQYH",
        "colab_type": "text"
      },
      "source": [
        "## Second style\n",
        "Using a Subclassed model and a GradientTape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vV0Hz2RV1C5",
        "colab_type": "text"
      },
      "source": [
        "Prepre the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0umywbPeW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "train_ds = train_ds.shuffle(60000).batch(32)\n",
        "test_ds = test_ds.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZgdwTLLwq1D",
        "colab_type": "text"
      },
      "source": [
        "Define a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRaR1rtpUgDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.flatten = Flatten(input_shape=(28, 28))\n",
        "    self.d1 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    return self.d1(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMFRp7CCTxmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7aIkldyT1S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZzldV1BV3Rs",
        "colab_type": "text"
      },
      "source": [
        "Training and testing routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcDHIccXUP_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEUmM7G6V7ae",
        "colab_type": "text"
      },
      "source": [
        "Prepare log writers (previously, these were handled by the callback)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGrEExdWV84_",
        "colab_type": "code",
        "outputId": "302de232-0769-4a25-ed31-d7fe67f27065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)\n",
        "\n",
        "train_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"train\"))\n",
        "test_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"test\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191028-231400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v-gMTCiwuBO",
        "colab_type": "text"
      },
      "source": [
        "Train and log summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rxTf4CyVKxK",
        "colab_type": "code",
        "outputId": "214dfae3-65e8-4115-d06d-d5bd90f4c6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  \n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "    \n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "  \n",
        "  with train_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "\n",
        "    # ====\n",
        "    # Demo: show how to use histogram summaries\n",
        "    # Create and log some random data\n",
        "    # Useful if you're attemping the extra credit question\n",
        "    # ====\n",
        "    data = tf.random.normal((32, 100))\n",
        "    tf.summary.histogram('random', \n",
        "                         data,\n",
        "                         step=epoch, \n",
        "                         description='Your description')\n",
        "    \n",
        "  with test_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "    \n",
        "  # Reset the metrics for the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.47127506136894226, Accuracy: 87.55500030517578, Test Loss: 0.31238049268722534, Test Accuracy: 91.39999389648438\n",
            "Epoch 2, Loss: 0.30420851707458496, Accuracy: 91.5433349609375, Test Loss: 0.2801072299480438, Test Accuracy: 92.2699966430664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrXOlQa5VWnq",
        "colab_type": "code",
        "outputId": "c8710904-cc86-438e-d5cd-81d713242844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6007\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8gMiumFmVk",
        "colab_type": "text"
      },
      "source": [
        "## 3a ReLU acticvation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Qo44iAFlEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_relu(x):\n",
        "  return tf.math.maximum(0.0,x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bm0Uo4zbKmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyJWP8dmKd3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import datetime \n",
        "import os\n",
        "\n",
        "def create_model(act):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation=act),\n",
        "    Dense(64, activation=act),\n",
        "    Dense(10, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZY5i0ZNSVCA",
        "colab_type": "code",
        "outputId": "afd199f5-8161-4c34-a7dd-10af29939a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###logs\n",
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191029-004750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS37CrTMTAH-",
        "colab_type": "text"
      },
      "source": [
        "#### run a experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4daPLt4RS4zf",
        "colab_type": "code",
        "outputId": "9d6de0e1-d67f-48cb-ca45-fc4fa48bb52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = create_model(my_relu) \n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False) \n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"relu\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 3.5603 - accuracy: 0.1522 - val_loss: 2.0766 - val_accuracy: 0.4711\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 1.6804 - accuracy: 0.6077 - val_loss: 1.2764 - val_accuracy: 0.6976\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 1.0507 - accuracy: 0.7389 - val_loss: 0.8501 - val_accuracy: 0.7777\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.7660 - accuracy: 0.7926 - val_loss: 0.6618 - val_accuracy: 0.8217\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.6281 - accuracy: 0.8253 - val_loss: 0.5621 - val_accuracy: 0.8421\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.5470 - accuracy: 0.8475 - val_loss: 0.4972 - val_accuracy: 0.8634\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4934 - accuracy: 0.8633 - val_loss: 0.4540 - val_accuracy: 0.8744\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4553 - accuracy: 0.8730 - val_loss: 0.4230 - val_accuracy: 0.8827\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4273 - accuracy: 0.8802 - val_loss: 0.3972 - val_accuracy: 0.8886\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4056 - accuracy: 0.8859 - val_loss: 0.3790 - val_accuracy: 0.8912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25a42d6048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3_jICfiTb7_",
        "colab_type": "text"
      },
      "source": [
        "#### run another experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1GDLVWRTZVK",
        "colab_type": "code",
        "outputId": "bfe534d5-fecc-429c-cfe0-b6af07d87836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model(\"tanh\") \n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"tanh\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 3.5536 - accuracy: 0.3125 - val_loss: 2.4331 - val_accuracy: 0.5323\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 2.0011 - accuracy: 0.5930 - val_loss: 1.6746 - val_accuracy: 0.6470\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 1.4703 - accuracy: 0.6970 - val_loss: 1.2818 - val_accuracy: 0.7454\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 1.1511 - accuracy: 0.7665 - val_loss: 1.0212 - val_accuracy: 0.7964\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.9335 - accuracy: 0.8059 - val_loss: 0.8397 - val_accuracy: 0.8257\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.7827 - accuracy: 0.8302 - val_loss: 0.7147 - val_accuracy: 0.8454\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.6787 - accuracy: 0.8469 - val_loss: 0.6278 - val_accuracy: 0.8612\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.6053 - accuracy: 0.8583 - val_loss: 0.5656 - val_accuracy: 0.8711\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.5516 - accuracy: 0.8677 - val_loss: 0.5185 - val_accuracy: 0.8776\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.5106 - accuracy: 0.8745 - val_loss: 0.4828 - val_accuracy: 0.8835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25a2d50fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOQ5YLmSUd8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w74IAgtDXFl8",
        "colab_type": "text"
      },
      "source": [
        "From the tensor board of relu and tanh activation function, we can see that in 10 epoches, model using relu as activation function tend to have higher accuracy and low loss than that using tanh. So I conclude that relu has a better performance in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L9jNtoxXFd7",
        "colab_type": "text"
      },
      "source": [
        "## 3b Optimizer and initalizer and soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bINZxXQ0keig",
        "colab_type": "text"
      },
      "source": [
        "### for Momentum and Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZq8sc3VHWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return my_relu(x)\n",
        "  \n",
        "  model = MyModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXXle8Nscfe9",
        "colab_type": "code",
        "outputId": "fdd260aa-51b7-4a6b-9946-66ad31451896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191029-005905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9rdaZatbc3i",
        "colab_type": "code",
        "outputId": "6c9dfbe5-a728-4263-b90e-b0ba9e2d3957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model(\"relu\")\n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"opt1\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 3.2595 - accuracy: 0.2337 - val_loss: 2.0334 - val_accuracy: 0.5338\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 1.6893 - accuracy: 0.6227 - val_loss: 1.3218 - val_accuracy: 0.6964\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 1.0927 - accuracy: 0.7306 - val_loss: 0.8918 - val_accuracy: 0.7821\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.8000 - accuracy: 0.7937 - val_loss: 0.6962 - val_accuracy: 0.8167\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.6501 - accuracy: 0.8275 - val_loss: 0.5814 - val_accuracy: 0.8445\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.5582 - accuracy: 0.8497 - val_loss: 0.5073 - val_accuracy: 0.8607\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4981 - accuracy: 0.8637 - val_loss: 0.4574 - val_accuracy: 0.8735\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.4575 - accuracy: 0.8728 - val_loss: 0.4256 - val_accuracy: 0.8819\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4286 - accuracy: 0.8804 - val_loss: 0.4024 - val_accuracy: 0.8868\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4073 - accuracy: 0.8856 - val_loss: 0.3825 - val_accuracy: 0.8911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25a312d518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V7k63ugB_Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ye6-KlJbiBo",
        "colab_type": "code",
        "outputId": "42ce52c5-01c7-443e-87f0-850e72234c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model(\"relu\")\n",
        "opt = Adam(learning_rate = 0.001, amsgrad=False)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"opt2\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4018 - accuracy: 0.8893 - val_loss: 0.1977 - val_accuracy: 0.9436\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.1696 - accuracy: 0.9512 - val_loss: 0.1510 - val_accuracy: 0.9551\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1309 - accuracy: 0.9617 - val_loss: 0.1366 - val_accuracy: 0.9575\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1087 - accuracy: 0.9678 - val_loss: 0.1189 - val_accuracy: 0.9644\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0951 - accuracy: 0.9713 - val_loss: 0.1052 - val_accuracy: 0.9690\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0833 - accuracy: 0.9737 - val_loss: 0.1079 - val_accuracy: 0.9692\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0748 - accuracy: 0.9764 - val_loss: 0.1071 - val_accuracy: 0.9689\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0667 - accuracy: 0.9789 - val_loss: 0.1058 - val_accuracy: 0.9693\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.1082 - val_accuracy: 0.9680\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0563 - accuracy: 0.9821 - val_loss: 0.1191 - val_accuracy: 0.9676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f259e86e358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPsRRzqbCdCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH-DbGbRDgoe",
        "colab_type": "text"
      },
      "source": [
        "From the tensor board we can see that both train and validation of momentum optimizer have lower acurracy and higher loss than those of Adam, indicating that in this case Adam has better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YPMEbPqklK_",
        "colab_type": "text"
      },
      "source": [
        "### For different initialize strategy :\n",
        "random normal, or glorot uniform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVvRphqDlI9c",
        "colab_type": "code",
        "outputId": "f61b2702-03b0-4049-89d6-24e68f1f517b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191029-010949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s_doo5uki72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###\n",
        "def create_model(initializer):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu', kernel_initializer=initializer),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_tBAWBnh6p",
        "colab_type": "code",
        "outputId": "3eb0c220-82cf-477d-9bb5-4b13dbdbea32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model(\"random_normal\")\n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"random_normal\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 3.8152 - accuracy: 0.1874 - val_loss: 2.0446 - val_accuracy: 0.4781\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 1.5779 - accuracy: 0.6202 - val_loss: 1.1930 - val_accuracy: 0.7022\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 1.0114 - accuracy: 0.7283 - val_loss: 0.8344 - val_accuracy: 0.7713\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.7568 - accuracy: 0.7908 - val_loss: 0.6596 - val_accuracy: 0.8184\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.6226 - accuracy: 0.8281 - val_loss: 0.5588 - val_accuracy: 0.8461\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.5406 - accuracy: 0.8517 - val_loss: 0.4930 - val_accuracy: 0.8635\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4872 - accuracy: 0.8657 - val_loss: 0.4514 - val_accuracy: 0.8746\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4507 - accuracy: 0.8758 - val_loss: 0.4212 - val_accuracy: 0.8802\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4237 - accuracy: 0.8828 - val_loss: 0.3963 - val_accuracy: 0.8879\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4031 - accuracy: 0.8884 - val_loss: 0.3778 - val_accuracy: 0.8925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2597290ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7kBvqk5nsyC",
        "colab_type": "code",
        "outputId": "a912aa72-9c99-4989-a4e4-87a70e1cc1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = create_model(\"glorot_uniform\")\n",
        "opt = SGD(learning_rate=0.001, momentum=0.0, nesterov=False)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "exp_dir = os.path.join(log_dir, \"glorot_uniform\")\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=exp_dir)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 3.4382 - accuracy: 0.2110 - val_loss: 2.0984 - val_accuracy: 0.4516\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 1.7358 - accuracy: 0.5924 - val_loss: 1.3562 - val_accuracy: 0.6850\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 1.1141 - accuracy: 0.7187 - val_loss: 0.8923 - val_accuracy: 0.7741\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.7996 - accuracy: 0.7928 - val_loss: 0.6796 - val_accuracy: 0.8149\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.6439 - accuracy: 0.8287 - val_loss: 0.5649 - val_accuracy: 0.8460\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.5535 - accuracy: 0.8492 - val_loss: 0.4950 - val_accuracy: 0.8629\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4954 - accuracy: 0.8624 - val_loss: 0.4515 - val_accuracy: 0.8728\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4560 - accuracy: 0.8720 - val_loss: 0.4182 - val_accuracy: 0.8811\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.4278 - accuracy: 0.8794 - val_loss: 0.3950 - val_accuracy: 0.8881\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4066 - accuracy: 0.8841 - val_loss: 0.3760 - val_accuracy: 0.8924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2597fd3eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPqs2ukTEtmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$log_dir\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG3dwHioF8od",
        "colab_type": "text"
      },
      "source": [
        "## 3b (optional)\n",
        "Demonstrate the vanishing gradient problem.\n",
        "\n",
        "Implement an especially deep neural network and train it on a simple dataset like MNIST. Choose activation functions, initialization strategies, and an optimizer that are likely to cause this behavior. Produce histograms of activations and gradients at various layers during training. What do you see? Next, adjust the parameters above to correct this behavior. Visualize and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCK8Yd0RGCpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='signoid'),\n",
        "    Dense(64, activation='signoid'),\n",
        "    Dense(64, activation='signoid'),\n",
        "    Dense(64, activation='signoid'),\n",
        "    Dense(64, activation='signoid'),\n",
        "    Dense(64, activation='signoid'),\n",
        "    Dense(10, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN9ZWV9bLGGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.SGD()\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig4ecE0XNG1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb763rI5NOSI",
        "colab_type": "code",
        "outputId": "6d348aad-a95a-4373-c053-c229ed4c24db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir = os.path.join(\"./tensorboard-logs/\", date)\n",
        "print(\"Writing logs to\", log_dir)\n",
        "\n",
        "train_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"train\"))\n",
        "test_writer = tf.summary.create_file_writer(os.path.join(log_dir, \"test\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing logs to ./tensorboard-logs/20191029-015105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZinxP7OrQFWR",
        "colab_type": "code",
        "outputId": "3bdcc434-2f2e-47d4-bffa-23fc48d86076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  \n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "    \n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "  \n",
        "  with train_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "\n",
        "    # ====\n",
        "    # Demo: show how to use histogram summaries\n",
        "    # Create and log some random data\n",
        "    # Useful if you're attemping the extra credit question\n",
        "    # ====\n",
        "    data = tf.random.normal((32, 100))\n",
        "    tf.summary.histogram('random', \n",
        "                         data,\n",
        "                         step=epoch, \n",
        "                         description='Your description')\n",
        "    \n",
        "  with test_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
        "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
        "    \n",
        "  # Reset the metrics for the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.25563400983810425, Accuracy: 92.61261749267578, Test Loss: 0.2339257150888443, Test Accuracy: 93.14857482910156\n",
            "Epoch 2, Loss: 0.18101826310157776, Accuracy: 94.74333190917969, Test Loss: 0.1860692948102951, Test Accuracy: 94.51000213623047\n",
            "Epoch 3, Loss: 0.1717109978199005, Accuracy: 94.97333526611328, Test Loss: 0.1680724322795868, Test Accuracy: 95.01000213623047\n",
            "Epoch 4, Loss: 0.1624779999256134, Accuracy: 95.25499725341797, Test Loss: 0.16029612720012665, Test Accuracy: 95.13999938964844\n",
            "Epoch 5, Loss: 0.15450261533260345, Accuracy: 95.5, Test Loss: 0.15948522090911865, Test Accuracy: 95.3499984741211\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}